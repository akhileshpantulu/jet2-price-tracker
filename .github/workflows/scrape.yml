# Runs the Jet2 scraper every 6 hours, commits fresh pricing data,
# which triggers the deploy workflow to rebuild the dashboard.
#
# You can also run it manually: Actions tab â†’ "Scrape Prices" â†’ Run workflow

name: Scrape Prices

on:
  schedule:
    # Runs at midnight, 6am, noon, 6pm UTC every day
    - cron: "0 0,6,12,18 * * *"
  workflow_dispatch: # Manual trigger button

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install dependencies
        run: |
          pip install playwright
          playwright install chromium --with-deps

      - name: Run scraper
        run: python backend/scraper.py

      - name: Commit updated pricing data
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add frontend/public/pricing_data.json
          # Only commit if there are changes
          git diff --staged --quiet || git commit -m "ðŸ”„ Update pricing data $(date -u +'%Y-%m-%d %H:%M UTC')"
          git push
